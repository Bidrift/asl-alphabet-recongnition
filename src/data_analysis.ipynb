{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and setting up data\n",
    "\n",
    "The first step is to download data into dataset folder using kaggle_downloader lib\n",
    "\n",
    "Make sure you have got the json API file in the main repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../kaggle.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.makedirs(\"../dataset\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
      "License(s): GPL-2.0\n",
      "Downloading asl-alphabet.zip to ../dataset\n",
      "100%|██████████████████████████████████████| 1.03G/1.03G [15:19<00:00, 1.49MB/s]\n",
      "100%|██████████████████████████████████████| 1.03G/1.03G [15:19<00:00, 1.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = data['username']\n",
    "os.environ['KAGGLE_KEY'] = data['key']\n",
    "!kaggle datasets download --unzip -p ../dataset/ grassknoted/asl-alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start setting up and analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the dataset and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 87000 files [00:22, 3856.37 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "train_src = \"../dataset/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "splitfolders.ratio(train_src, output=\"datasets/asl_alphabet\",\n",
    "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "Based on a visual analysis of the data in Kaggle, we notice that every class has 3000 photos, therefore the data is balanced.\n",
    "\n",
    "We notice as well that the images have different coloring, environment, and with proper randomization in preprocessing, we will have a useful dataset\n",
    "\n",
    "The images have a resolution of 200x200 and we simply will need to convert them to 32x32 and possibly grayscale them for better training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
